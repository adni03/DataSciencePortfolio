<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>Fake News Classification using LSTMs - Data Science Portfolio</title><meta name="Description" content="Hugo theme - LoveIt"><meta property="og:title" content="Fake News Classification using LSTMs" />
<meta property="og:description" content="Classifying news articles as real or fake using Natural Language Processing techniques." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://adni03.github.io/Portfolio/fake-news-classification/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-04T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-09-04T00:00:00+00:00" /><meta property="og:site_name" content="LoveIt" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Fake News Classification using LSTMs"/>
<meta name="twitter:description" content="Classifying news articles as real or fake using Natural Language Processing techniques."/>
<meta name="application-name" content="Aditya Nittala">
<meta name="apple-mobile-web-app-title" content="Aditya Nittala"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="canonical" href="https://adni03.github.io/Portfolio/fake-news-classification/" /><link rel="prev" href="https://adni03.github.io/Portfolio/neural-style-transfer/" /><link rel="stylesheet" href="/Portfolio/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Fake News Classification using LSTMs",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/adni03.github.io\/Portfolio\/fake-news-classification\/"
        },"image": ["https:\/\/adni03.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "LSTMs, TensorFlow, nltk","wordcount":  854 ,
        "url": "https:\/\/adni03.github.io\/Portfolio\/fake-news-classification\/","datePublished": "2022-09-04T00:00:00+00:00","dateModified": "2022-09-04T00:00:00+00:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": "https:\/\/adni03.github.io\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "Aditya Nittala"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/Portfolio/" title="Data Science Portfolio"><span class="header-title-pre"><i class='fa-solid fa-spinner fa-pulse' aria-hidden='true'></i></span> Aditya Nittala</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/Portfolio/posts/"> Projects </a><a class="menu-item" href="/Portfolio/categories/"> Categories </a><a class="menu-item" href="/Portfolio/tags/"> Tags </a><a class="menu-item" href="/Portfolio/about/"> About </a><a class="menu-item" href="https://github.com/adni03" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/Portfolio/" title="Data Science Portfolio"><span class="header-title-pre"><i class='fa-solid fa-spinner fa-pulse' aria-hidden='true'></i></span> Aditya Nittala</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/Portfolio/posts/" title="">Projects</a><a class="menu-item" href="/Portfolio/categories/" title="">Categories</a><a class="menu-item" href="/Portfolio/tags/" title="">Tags</a><a class="menu-item" href="/Portfolio/about/" title="">About</a><a class="menu-item" href="https://github.com/adni03" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content always-active" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Fake News Classification using LSTMs</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/Portfolio/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Aditya Nittala</a></span>&nbsp;<span class="post-category">included in <a href="/Portfolio/categories/natural-language-processing/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Natural Language Processing</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2022-09-04">2022-09-04</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;854 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="featured-image"><img
        class="lazyload"
        src="/Portfolio/svg/loading.min.svg"
        data-src="/Portfolio/fake-news-classification/fake.png"
        data-srcset="/Portfolio/fake-news-classification/fake.png, /Portfolio/fake-news-classification/fake.png 1.5x, /Portfolio/fake-news-classification/fake.png 2x"
        data-sizes="auto"
        alt="/Portfolio/fake-news-classification/fake.png"
        title="/Portfolio/fake-news-classification/fake.png" width="1262" height="629" /></div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-the-dataset">1. The Dataset</a></li>
    <li><a href="#2-data-cleaning">2. Data Cleaning</a></li>
    <li><a href="#3-exploratory-data-analysis">3. Exploratory Data Analysis</a>
      <ul>
        <li><a href="#word-cloud-for-fake-news">Word Cloud for fake news</a></li>
        <li><a href="#word-cloud-for-real-news">Word Cloud for real news</a></li>
      </ul>
    </li>
    <li><a href="#4-preparing-data-by-tokenization-and-padding">4. Preparing data by tokenization and padding</a></li>
    <li><a href="#4-building-the-model">4. Building the Model</a>
      <ul>
        <li><a href="#code">Code</a></li>
      </ul>
    </li>
    <li><a href="#5-training-and-performance">5. Training and Performance</a>
      <ul>
        <li><a href="#code-1">Code</a></li>
      </ul>
    </li>
    <li><a href="#6-results">6. Results</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>Classifying news articles as real or fake using Natural Language Processing techniques.</p>
<p>With the advent of the internet, the world has never been so informed. News can be shared across the globe within seconds through online sources such at news websites, blog posts, twitter etc. But, the grim reality is that there is a lot of misinformation and disinformation on the internet. Most recently, during the peak of the COVID-19 pandemic, misinformatino about vaccines spread like wildfire. Why don&rsquo;t we use NLP to combat this?</p>
<h2 id="1-the-dataset">1. The Dataset</h2>
<p>The dataset consists of news article gathers from some of the major sources in the United States such as The Washington Post, Reuters, New York Times, etc. These articles cover the following topics:</p>
<ul>
<li>Politics</li>
<li>World News</li>
<li>Government News</li>
<li>Middle-east News</li>
</ul>
<p>The structure of the dataset is:</p>
<ul>
<li>title: Title of the news article</li>
<li>text: The content of the article (whole)</li>
<li>subject: One of the above mentioned topics</li>
<li>date: Date of publish</li>
<li>isfake: A binary varible where 1 is Fake and 0 is Real</li>
</ul>
<h2 id="2-data-cleaning">2. Data Cleaning</h2>
<p>Each news article from the corpus was stripped down by removing the stopwords. The list of stopwords were obtained from the <code>nltk</code> and the <code>gensim</code> libraries.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="c1"># download stopwords</span>
</span></span><span class="line"><span class="cl">    <span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&#34;stopwords&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Obtain additional stopwords from nltk</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
</span></span><span class="line"><span class="cl">    <span class="n">stop_words</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">stop_words</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;from&#39;</span><span class="p">,</span> <span class="s1">&#39;subject&#39;</span><span class="p">,</span> <span class="s1">&#39;re&#39;</span><span class="p">,</span> <span class="s1">&#39;edu&#39;</span><span class="p">,</span> <span class="s1">&#39;use&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">gensim</span><span class="o">.</span><span class="n">parsing</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">STOPWORDS</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The news article was tokenized and each token was checked against the list of stopwords. The remaining tokens were stored in a list and then joined to form a <em>clean</em> article.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="c1"># Remove stopwords and remove words with 2 or less characters</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">gensim</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">simple_preprocess</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">gensim</span><span class="o">.</span><span class="n">parsing</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">STOPWORDS</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span> <span class="ow">and</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">result</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;original&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">preprocess</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean_joined&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&#34; &#34;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="3-exploratory-data-analysis">3. Exploratory Data Analysis</h2>
<p>To get a better understanding of the dataset, <code>WordCloud</code> was used to see the most frequently used terms in the fake and real news articles.</p>
<h3 id="word-cloud-for-fake-news">Word Cloud for fake news</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="c1"># plot the word cloud for text that is fake</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span> 
</span></span><span class="line"><span class="cl">    <span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">max_words</span> <span class="o">=</span> <span class="mi">2000</span> <span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">1600</span> <span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">800</span> <span class="p">,</span> <span class="n">stopwords</span> <span class="o">=</span> <span class="n">stop_words</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="s2">&#34; &#34;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">isfake</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">clean_joined</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wc</span><span class="p">,</span> <span class="n">interpolation</span> <span class="o">=</span> <span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><figure><a class="lightgallery" href="/Portfolio/fake-news-classification/wc_fake.png" title="/Portfolio/fake-news-classification/wc_fake.png" data-thumbnail="/Portfolio/fake-news-classification/wc_fake.png" data-sub-html="<h2>Fake News</h2>">
        <img
            class="lazyload"
            src="/Portfolio/svg/loading.min.svg"
            data-src="/Portfolio/fake-news-classification/wc_fake.png"
            data-srcset="/Portfolio/fake-news-classification/wc_fake.png, /Portfolio/fake-news-classification/wc_fake.png 1.5x, /Portfolio/fake-news-classification/wc_fake.png 2x"
            data-sizes="auto"
            alt="/Portfolio/fake-news-classification/wc_fake.png" width="1164" height="601" />
    </a><figcaption class="image-caption">Fake News</figcaption>
    </figure></p>
<h3 id="word-cloud-for-real-news">Word Cloud for real news</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="c1"># plot the word cloud for text that is fake</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span> 
</span></span><span class="line"><span class="cl">    <span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">max_words</span> <span class="o">=</span> <span class="mi">2000</span> <span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">1600</span> <span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">800</span> <span class="p">,</span> <span class="n">stopwords</span> <span class="o">=</span> <span class="n">stop_words</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="s2">&#34; &#34;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">isfake</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">clean_joined</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wc</span><span class="p">,</span> <span class="n">interpolation</span> <span class="o">=</span> <span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><figure><a class="lightgallery" href="/Portfolio/fake-news-classification/wc_real.png" title="/Portfolio/fake-news-classification/wc_real.png" data-thumbnail="/Portfolio/fake-news-classification/wc_real.png" data-sub-html="<h2>Real News</h2>">
        <img
            class="lazyload"
            src="/Portfolio/svg/loading.min.svg"
            data-src="/Portfolio/fake-news-classification/wc_real.png"
            data-srcset="/Portfolio/fake-news-classification/wc_real.png, /Portfolio/fake-news-classification/wc_real.png 1.5x, /Portfolio/fake-news-classification/wc_real.png 2x"
            data-sizes="auto"
            alt="/Portfolio/fake-news-classification/wc_real.png" width="1164" height="601" />
    </a><figcaption class="image-caption">Real News</figcaption>
    </figure></p>
<h2 id="4-preparing-data-by-tokenization-and-padding">4. Preparing data by tokenization and padding</h2>
<p>Once the data is cleaned, I created train-test splits using <code>train_test_split</code> from the <code>sklearn</code> library. Then a Tokenizer from the <code>nltk</code> library was used to generate sequences of tokenized words.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span> <span class="o">=</span> <span class="n">total_words</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_sequences</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_sequences</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Next, each sequence had to be padded to the maximum length of article in the news corpus.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="n">padded_train</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">train_sequences</span><span class="p">,</span><span class="n">maxlen</span> <span class="o">=</span> <span class="mi">4405</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;post&#39;</span><span class="p">,</span> <span class="n">truncating</span> <span class="o">=</span> <span class="s1">&#39;post&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">padded_test</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">test_sequences</span><span class="p">,</span><span class="n">maxlen</span> <span class="o">=</span> <span class="mi">4405</span><span class="p">,</span> <span class="n">truncating</span> <span class="o">=</span> <span class="s1">&#39;post&#39;</span><span class="p">)</span> 
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="4-building-the-model">4. Building the Model</h2>
<p>Now for the fun part!
The model I used for this task was a <code>Bidirectional LSTM</code> with 128 units. I had to use a bidirectional model because the length of these articles are quite long and so I wanted to capture long term dependencies from the <em>future</em> and the <em>past</em>. To train the model I used the <code>TensorFlow</code> framework. An <code>Embedding</code> layer was added before the BiLSTM layer to convert the sequences into Embeddings for the model to train on. Since this is a binary classification problem, the output layer has one unit with a <code>sigmoid</code> activation. The <code>adam</code> optimizer was used and the loss function was set to <code>binary_crossentropy</code>.</p>
<h3 id="code">Code</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="c1"># Sequential Model</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># embeddidng layer</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">total_words</span><span class="p">,</span> <span class="n">output_dim</span> <span class="o">=</span> <span class="mi">128</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># model.add(Embedding(total_words, output_dim = 240))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Bi-Directional RNN and LSTM</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Dense layers</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="5-training-and-performance">5. Training and Performance</h2>
<p>The model was trained for 2 epochs with a validation split of 0.1 and a batch_size of 64. The trained model was then evaluated on the test set by obtaining the sigmoid outputs. If the value is greater than 0.5, classify as fake.</p>
<h3 id="code-1">Code</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="c1"># train the model</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">padded_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">validation_split</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># if the predicted value is &gt;0.5 it is real else it is fake</span>
</span></span><span class="line"><span class="cl">    <span class="n">prediction</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">prediction</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">prediction</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># getting the accuracy</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span> <span class="n">prediction</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Model Accuracy : &#34;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">Model</span> <span class="n">Accuracy</span> <span class="p">:</span>  <span class="mf">0.9968819599109131</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="6-results">6. Results</h2>
<p>With a test accuracy of <code>99.6%</code>, this model does a great job at detecting if a news article is real or fake.</p></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2022-09-04</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://adni03.github.io/Portfolio/fake-news-classification/" data-title="Fake News Classification using LSTMs" data-hashtags="LSTMs,TensorFlow,nltk"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://adni03.github.io/Portfolio/fake-news-classification/" data-hashtag="LSTMs"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://adni03.github.io/Portfolio/fake-news-classification/" data-title="Fake News Classification using LSTMs"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://adni03.github.io/Portfolio/fake-news-classification/" data-title="Fake News Classification using LSTMs"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://adni03.github.io/Portfolio/fake-news-classification/" data-title="Fake News Classification using LSTMs" data-image="fake.png"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/Portfolio/tags/lstms/">LSTMs</a>,&nbsp;<a href="/Portfolio/tags/tensorflow/">TensorFlow</a>,&nbsp;<a href="/Portfolio/tags/nltk/">nltk</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/Portfolio/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/Portfolio/neural-style-transfer/" class="prev" rel="prev" title="Neural Style Transfer"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>Neural Style Transfer</a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/Portfolio/" target="_blank">Aditya Nittala</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/algoliasearch@4.13.1/dist/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"lightgallery":true,"search":{"algoliaAppID":"PASDMWALPK","algoliaIndex":"index.en","algoliaSearchKey":"b42948e51daaa93df92381c8e2ac0f93","highlightTag":"em","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"algolia"}};</script><script type="text/javascript" src="/Portfolio/js/theme.min.js"></script></body>
</html>
